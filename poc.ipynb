{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fe40e4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d307312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "KURTOSIS_WINDOW = \"720D\"\n",
    "DATA_FILE = 'crsp.csv'\n",
    "FAMA_FRENCH_FACTORS = 'F-F_Research_Data_Factors.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into memory\n",
    "csrp = pd.read_csv(DATA_FILE)\n",
    "csrp = csrp[['permno', 'comnam', 'date', 'ret', 'dlret']]\n",
    "\n",
    "csrp['permno'] = pd.to_numeric(csrp['permno'], errors='coerce')\n",
    "csrp['ret'] = pd.to_numeric(csrp['ret'], errors='coerce')\n",
    "csrp['dlret'] = pd.to_numeric(csrp['dlret'], errors='coerce')\n",
    "csrp['date'] = pd.to_datetime(csrp['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fama french factors into memory\n",
    "ff_factors = pd.read_csv(FAMA_FRENCH_FACTORS)\n",
    "ff_factors['date'] = pd.to_datetime(ff_factors['date'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4359fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "# if we have multiple entries for the same permno and date, take mean \n",
    "csrp = csrp.groupby(['permno', 'date']).agg({\n",
    "    'ret': 'mean',      \n",
    "    'dlret': 'mean',    \n",
    "}).reset_index()\n",
    "\n",
    "csrp['date'] = csrp['date'].dt.to_period('M')\n",
    "ff_factors['date'] = ff_factors['date'].dt.to_period('M')\n",
    "\n",
    "# sync factors and data\n",
    "common_dates = pd.Series(list(set(csrp['date']).intersection(set(ff_factors['date']))))\n",
    "csrp = csrp[csrp['date'].isin(common_dates)]\n",
    "ff_factors = ff_factors[ff_factors['date'].isin(common_dates)]\n",
    "\n",
    "# shift csrp values by one month\n",
    "csrp = csrp.sort_values(['permno', 'date'])\n",
    "\n",
    "csrp['ret'] = csrp.groupby('permno')['ret'].transform(lambda x: x.shift(-1))\n",
    "csrp['dlret'] = csrp.groupby('permno')['dlret'].transform(lambda x: x.shift(-1))\n",
    "\n",
    "# adjust scale of ff factors\n",
    "ff_factors['MKT_RF'] = ff_factors['MKT_RF'] / 100\n",
    "ff_factors['SMB'] = ff_factors['SMB'] / 100\n",
    "ff_factors['HML'] = ff_factors['HML'] / 100\n",
    "ff_factors['RF'] = ff_factors['RF'] / 100\n",
    "\n",
    "# remove the last month from csrp\n",
    "last_month = csrp['date'].max()\n",
    "csrp = csrp[csrp['date'] < last_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461ab92",
   "metadata": {},
   "source": [
    "##### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first dates should be alligned\n",
    "print(csrp.sort_values('date').head())\n",
    "print(ff_factors.sort_values('date').head())\n",
    "\n",
    "# there should be no NaN in ff_factors, last date in data should be NaN and last date should allign\n",
    "print(csrp.sort_values('date').tail())  \n",
    "print(ff_factors.tail()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3437e",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kurtosis(df: pd.DataFrame):\n",
    "    df['kurtosis'] = None\n",
    "\n",
    "    for _, group in df.groupby('permno'):\n",
    "        k = group.set_index('date').to_timestamp()['ret'].rolling(window=KURTOSIS_WINDOW).kurt()\n",
    "        df.loc[group.index, 'kurtosis'] = k.values\n",
    "\n",
    "    return df.dropna(subset=['kurtosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a724f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate kurtosis\n",
    "csrp = calculate_kurtosis(csrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign quantiles based on kurtosis for each month\n",
    "csrp['quantile'] = csrp.groupby('date')['kurtosis'].transform(\n",
    "    lambda x: pd.qcut(x, q=10, labels=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41d7bd",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate returns for each quantile (assuming long position and equal weights)\n",
    "historical_quantile_returns_table = csrp.groupby(['date', 'quantile']).agg({'ret': 'mean', 'kurtosis':'mean'}).reset_index()\n",
    "\n",
    "historical_quantile_returns = []\n",
    "historical_quantile_kurtosis = []\n",
    "\n",
    "for quantile in historical_quantile_returns_table['quantile'].unique():\n",
    "    quantile_data = historical_quantile_returns_table[historical_quantile_returns_table['quantile'] == quantile]\n",
    "    historical_quantile_kurtosis.append(quantile_data['kurtosis'].mean())\n",
    "    historical_quantile_returns.append(quantile_data['ret'].mean())\n",
    "\n",
    "\n",
    "plot_data = [[f\"Q{i+1}\", f\"{historical_quantile_returns[i]:.4f}\", f\"{historical_quantile_kurtosis[i]:.4f}\"] for i in range(10)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=plot_data,\n",
    "    colLabels=[\"Quantile\", \"Mean Return (All Time)\", \"Mean Kurtosis (All Time)\"],\n",
    "    loc=\"center\",\n",
    "    cellLoc=\"center\"\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.auto_set_column_width(col=list(range(len(plot_data[0]))))\n",
    "\n",
    "plt.title(\"Quantile Statistics Table\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9117962",
   "metadata": {},
   "source": [
    "Quantiles with higher kurtosis appear to perform better than those with low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73acc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate autocorrelation of kurtosis\n",
    "ac1 = csrp.groupby('permno')['kurtosis'].apply(lambda x: x.autocorr(lag=1)).mean()\n",
    "\n",
    "print(\"Mean autocorrelation of kurtosis: \", ac1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501442f",
   "metadata": {},
   "source": [
    "Autocorrelation of kurtosis appears to be high, indicating we could try using it as a signal for portfolio creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb792368",
   "metadata": {},
   "source": [
    "### Portfolio creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_portfolio(df: pd.DataFrame, long, short = None):\n",
    "    long_portfolio = df[df['quantile'].isin(long)].copy()\n",
    "    long_portfolio.loc[:, 'position'] = 'long'  \n",
    "\n",
    "    if short is not None:\n",
    "        short_portfolio = df[df['quantile'].isin(short)].copy()\n",
    "        short_portfolio.loc[:, 'position'] = 'short'  \n",
    "        portfolio = pd.concat([long_portfolio, short_portfolio], axis=0)\n",
    "    else:\n",
    "        portfolio = long_portfolio\n",
    "\n",
    "    return portfolio\n",
    "\n",
    "def calculate_portfolio_returns(portfolio: pd.DataFrame):\n",
    "    portfolio = portfolio.copy()\n",
    "\n",
    "    # if ret is NaN and dlret is not NaN, set ret to 0 \n",
    "    mask_delist = portfolio['dlret'].notna() & portfolio['ret'].isna()\n",
    "    portfolio.loc[mask_delist, 'ret'] = 0\n",
    "\n",
    "    # drop any rows where both ret and dlret are NaN \n",
    "    portfolio = portfolio.dropna(subset=['ret'])\n",
    "\n",
    "    # fill dlret NaNs with 0\n",
    "    portfolio['dlret'] = portfolio['dlret'].fillna(0)\n",
    "\n",
    "    # calculate month's total return\n",
    "    portfolio['total_return'] = (1 + portfolio['ret']) * (1 + portfolio['dlret']) - 1\n",
    "\n",
    "    # calculate mean return for long and short positions\n",
    "    long_return = portfolio[portfolio['position'] == 'long']['total_return'].mean()\n",
    "    short_return = portfolio[portfolio['position'] == 'short']['total_return'].mean()\n",
    "\n",
    "    if pd.isna(short_return):\n",
    "        short_return = 0\n",
    "\n",
    "    portfolio_return = long_return - short_return\n",
    "\n",
    "    return portfolio_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_small_returns = []\n",
    "portfolio_large_returns = []\n",
    "quantile_returns = {q: [] for q in range(10)}\n",
    "\n",
    "# Group data by month\n",
    "grouped_months = csrp.groupby('date')\n",
    "\n",
    "for month, month_data in grouped_months:\n",
    "    next_month = month + 1\n",
    "\n",
    "    # Create portfolios\n",
    "    portfolio_small = create_portfolio(month_data, [9], [0])\n",
    "    portfolio_large = create_portfolio(month_data, [9, 8], [0, 1])\n",
    "\n",
    "    # Calculate portfolio returns\n",
    "    portfolio_small_returns.append((next_month, calculate_portfolio_returns(portfolio_small)))\n",
    "    portfolio_large_returns.append((next_month, calculate_portfolio_returns(portfolio_large)))\n",
    "\n",
    "    # Calculate quantile returns\n",
    "    for q in range(10):\n",
    "        quantile_data = month_data[month_data['quantile'] == q]\n",
    "        quantile_data = quantile_data.assign(position=\"long\")\n",
    "        quantile_returns[q].append((next_month, calculate_portfolio_returns(quantile_data)))\n",
    "\n",
    "# Convert results to time series\n",
    "port_small_series = pd.Series(dict(portfolio_small_returns)).sort_index()\n",
    "port_large_series = pd.Series(dict(portfolio_large_returns)).sort_index()\n",
    "quantile_series = {q: pd.Series(dict(returns)).sort_index() for q, returns in quantile_returns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(port_small_series.index.to_timestamp(), port_small_series.values, label=\"Portfolio Small (Q10 - Q1)\", color=\"blue\")\n",
    "plt.plot(port_large_series.index.to_timestamp(), port_large_series.values, label=\"Portfolio Large (Q10, Q9 - Q1, Q2)\", color=\"green\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.title(\"Portfolio Returns Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot quantile returns_\n",
    "plt.figure(figsize=(12, 6))\n",
    "for q, series in quantile_series.items():\n",
    "    plt.plot(series.index.to_timestamp(), series.values, label=f\"Quantile {q+1}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.title(\"Quantile Returns Over Time\")\n",
    "plt.legend(loc=\"upper left\", fontsize=\"small\", ncol=2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean return for each quantile and portfolio\n",
    "mean_port_small = port_small_series.mean()\n",
    "mean_port_large = port_large_series.mean()\n",
    "mean_quantiles = {q: series.mean() for q, series in quantile_series.items()}\n",
    "\n",
    "labels = [\"Portfolio Small\", \"Portfolio Large\"] + [f\"Quantile {q+1}\" for q in range(10)]\n",
    "means = [mean_port_small, mean_port_large] + [mean_quantiles[q] for q in range(10)]\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, means, color=[\"blue\", \"green\"] + [\"orange\"] * 10)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Mean Return\")\n",
    "plt.title(\"Mean Returns for Portfolios and Quantiles\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9ae85",
   "metadata": {},
   "source": [
    "### Portfolio evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define famma french\n",
    "def fama_french(data: pd.Series, factors):\n",
    "    data = data.reset_index()  \n",
    "    data.columns = ['date', 'total_return']  \n",
    "\n",
    "    # match date with factors\n",
    "    regression_in = pd.merge(data, factors, on='date', how='left')\n",
    "\n",
    "    # Compute excess return\n",
    "    regression_in['excess_return'] = regression_in['total_return'] - regression_in['RF']\n",
    "\n",
    "    # raise exception if any of the critical columns have NaN values\n",
    "    if regression_in[['total_return', 'MKT_RF', 'SMB', 'HML', 'RF', 'excess_return']].isna().any().any():\n",
    "        raise ValueError(\"NaN values found in critical columns during Fama-French regression.\")\n",
    "\n",
    "    X = regression_in[['MKT_RF', 'SMB', 'HML']]\n",
    "    X = X.apply(pd.to_numeric, errors='raise')\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "\n",
    "    y = pd.to_numeric(regression_in['excess_return'], errors='raise')\n",
    "\n",
    "    # Run regression\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model\n",
    "\n",
    "def capm(data: pd.Series, factors):\n",
    "    data = data.reset_index()  \n",
    "    data.columns = ['date', 'total_return']  \n",
    "\n",
    "    # match date with factors\n",
    "    regression_in = pd.merge(data, factors, on='date', how='left')\n",
    "\n",
    "    # Compute excess return\n",
    "    regression_in['excess_return'] = regression_in['total_return'] - regression_in['RF']\n",
    "\n",
    "    # raise exception if any of the critical columns have NaN values\n",
    "    if regression_in[['total_return', 'MKT_RF', 'RF', 'excess_return']].isna().any().any():\n",
    "        raise ValueError(\"NaN values found in critical columns during CAPM regression.\")\n",
    "\n",
    "    X = sm.add_constant(regression_in['MKT_RF'], has_constant='add')\n",
    "    y = pd.to_numeric(regression_in['excess_return'], errors='raise')\n",
    "\n",
    "    # Run regression\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bfda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find alphas for portfolios\n",
    "portfolio_small_model = fama_french(port_small_series, ff_factors)\n",
    "portfolio_large_model = fama_french(port_large_series, ff_factors)\n",
    "\n",
    "portfolio_alphas = [portfolio_small_model.params['const'], portfolio_large_model.params['const']]\n",
    "quantile_alphas = []\n",
    "\n",
    "portfolio_tvalues = [\n",
    "    portfolio_small_model.tvalues['const'],\n",
    "    portfolio_large_model.tvalues['const']\n",
    "]\n",
    "quantile_tvalues = []\n",
    "\n",
    "# find alphas for quantiles\n",
    "for q in range(10):\n",
    "    model = fama_french(quantile_series[q], ff_factors)\n",
    "    quantile_alphas.append(model.params['const'])\n",
    "    quantile_tvalues.append(model.tvalues['const'])\n",
    "\n",
    "\n",
    "# find betas for portfolios\n",
    "portfolio_small_beta_model = capm(port_small_series, ff_factors)\n",
    "portfolio_large_beta_model = capm(port_large_series, ff_factors)\n",
    "\n",
    "portfolio_betas = [portfolio_small_beta_model.params['MKT_RF'], portfolio_large_beta_model.params['MKT_RF']]\n",
    "quantile_betas = []\n",
    "\n",
    "portfolio_tvalues_beta = [\n",
    "    portfolio_small_beta_model.tvalues['MKT_RF'],\n",
    "    portfolio_large_beta_model.tvalues['MKT_RF']\n",
    "]\n",
    "quantile_tvalues_beta = []\n",
    "\n",
    "# find betas for quantiles\n",
    "for q in range(10):\n",
    "    model = capm(quantile_series[q], ff_factors)\n",
    "    quantile_betas.append(model.params['MKT_RF'])\n",
    "    quantile_tvalues_beta.append(model.tvalues['MKT_RF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot alphas and betas\n",
    "labels = [\"Portfolio Small\", \"Portfolio Large\"] + [f\"Quantile {q+1}\" for q in range(10)]\n",
    "alphas = portfolio_alphas + quantile_alphas\n",
    "tvalues = portfolio_tvalues + quantile_tvalues\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(labels, alphas, color=[\"brown\", \"purple\"] + [\"darkblue\"] * 10)\n",
    "\n",
    "for bar, alpha, tvalue in zip(bars, alphas, tvalues):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"t={tvalue:.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Alpha\")\n",
    "plt.title(\"Alphas and t-values for Portfolios and Quantiles\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# create charts for betas\n",
    "labels = [\"Portfolio Small\", \"Portfolio Large\"] + [f\"Quantile {q+1}\" for q in range(10)]\n",
    "betas = portfolio_betas + quantile_betas\n",
    "tvalues_beta = portfolio_tvalues_beta + quantile_tvalues_beta\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(labels, betas, color=[\"brown\", \"purple\"] + [\"darkblue\"] * 10)\n",
    "\n",
    "for bar, beta, tvalue in zip(bars, betas, tvalues_beta):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"t={tvalue:.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Beta (CAPM)\")\n",
    "plt.title(\"Betas and t-values for Portfolios and Quantiles\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b20720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sharpe ratio\n",
    "def sharpe_ratio(data: pd.Series, factors):\n",
    "    data = data.reset_index()  \n",
    "    data.columns = ['date', 'total_return']  \n",
    "\n",
    "    # match date with factors\n",
    "    returns_in = pd.merge(data, factors, on='date', how='left')\n",
    "\n",
    "    # Compute excess return\n",
    "    returns_in['excess_return'] = returns_in['total_return'] - returns_in['RF']\n",
    "\n",
    "    # return sharpe ratio\n",
    "    return returns_in['excess_return'].mean() / returns_in['excess_return'].std() * np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sharpe ratio for portfolios and quantiles\n",
    "portfolio_small_sharpe = sharpe_ratio(port_small_series, ff_factors)\n",
    "portfolio_large_sharpe = sharpe_ratio(port_large_series, ff_factors)\n",
    "quantile_sharpe = [sharpe_ratio(quantile_series[q], ff_factors) for q in range(10)]\n",
    "\n",
    "# create bar chart for sharpe ratio\n",
    "labels = [\"Portfolio Small\", \"Portfolio Large\"] + [f\"Quantile {q+1}\" for q in range(10)]\n",
    "sharpe_values = [portfolio_small_sharpe, portfolio_large_sharpe] + quantile_sharpe   \n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(labels, sharpe_values, color=[\"orange\", \"purple\"] + [\"brown\"] * 10)\n",
    "for bar, tvalue in zip(bars, sharpe_values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{tvalue:.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10\n",
    "    )\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Sharpe Ratio (Annualized)\")\n",
    "plt.title(\"Sharpe Ratios for Portfolios and Quantiles (Annualized)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
